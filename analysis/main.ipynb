{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f78a15bc-b4be-4159-bfee-d68cfa29575e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Coverage Monitor\n",
    "\n",
    "Problem statement\n",
    "\n",
    "Approach\n",
    "\n",
    "Who are we?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e605db4-0f31-4df1-a78f-a50594a3c9a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0609c33-3f13-4585-a162-385b5159ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# benchmark directory\n",
    "benchmark_loc = \"/Users/IceCream/Documents/hw22_fuzzing/benchmark\"\n",
    "\n",
    "# studied project\n",
    "proj = \"libpng-1.6.37-setting7\"\n",
    "proj_loc = os.path.join(benchmark_loc, proj)\n",
    "\n",
    "# output directory\n",
    "out_loc = os.path.join(proj_loc, \"analysis\")\n",
    "if not os.path.exists(out_loc):\n",
    "    os.makedirs(out_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c71988-c3b6-408c-888a-0f7ce73ad099",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Lauching AFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5680ed02-92dd-4c35-adeb-6cdd7e7c9bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# afl driver goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6c971-f216-4467-a5ff-5e59b4bef511",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Monitoring executions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7f569-6afd-4194-9bc6-5d17c504482f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 1. Collecting coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98802ce2-0b9c-4b31-b7a3-89e85fddffc2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing execution count...\n",
      "exec_c (534184, 3) & spectra (2405, 4)\n",
      "counter at 1000\n",
      "counter at 2000\n",
      "counter at 3000\n",
      "counter at 4000\n",
      "counter at 5000\n",
      "counter at 6000\n",
      "counter at 7000\n",
      "counter at 8000\n",
      "counter at 9000\n",
      "counter at 10000\n",
      "counter at 11000\n",
      "counter at 12000\n",
      "counter at 13000\n",
      "counter at 14000\n",
      "counter at 15000\n",
      "counter at 16000\n",
      "counter at 17000\n",
      "counter at 18000\n",
      "counter at 19000\n",
      "counter at 20000\n",
      "counter at 21000\n",
      "counter at 22000\n",
      "counter at 23000\n",
      "counter at 24000\n",
      "counter at 25000\n",
      "counter at 26000\n",
      "counter at 27000\n",
      "counter at 28000\n",
      "counter at 29000\n",
      "counter at 30000\n",
      "counter at 31000\n",
      "spectra (2405, 4)\n",
      "exec_c (25569, 3) \n",
      "19.864296913146973\n"
     ]
    }
   ],
   "source": [
    "%run cov_tracker.ipynb\n",
    "\n",
    "import time\n",
    "\n",
    "'''\n",
    "Process code coverage and store the output into cov.csv and exec_c.csv for coverage and execution counts \n",
    "[\"cid\", \"file\", \"line\", \"fn\"]\n",
    "'''\n",
    "def process_cov(proj_loc, out_loc):\n",
    "    global df_exec_c, fn_dict\n",
    "    \n",
    "    raw_data_loc = os.path.join(out_loc, 'raw')\n",
    "    spectra_csv = os.path.join(raw_data_loc, 'spectra_csv')\n",
    "    exec_c_csv = os.path.join(raw_data_loc, 'exec_c.csv')\n",
    "    if not os.path.exists(raw_data_loc):\n",
    "        os.makedirs(raw_data_loc)\n",
    "    \n",
    "    if not os.path.exists(exec_c_csv) or not os.path.exists(spectra_csv):\n",
    "        # collect the code coverage and store it in `df_exec_c`\n",
    "        print(\"Collecting coverage results...\")\n",
    "        collect_cov(proj_loc)\n",
    "        # preprocess the data before computing the individual count\n",
    "        print(\"Preprocessing coverage...\")\n",
    "        df_spectra, df_exec_c = preprocess_cov(spectra_csv, exec_c_csv)\n",
    "    else:\n",
    "        df_spectra = pd.read_csv(spectra_csv)\n",
    "        df_exec_c = pd.read_csv(exec_c_csv)\n",
    "    \n",
    "    # from cumulative count to individual count\n",
    "    print(\"Computing execution count...\")\n",
    "    print(\"exec_c {} & spectra {}\".format(df_exec_c.shape, df_spectra.shape))\n",
    "    # sorted reverse, start from the last trace_id\n",
    "    # sampling\n",
    "    # df_exec_c = df_exec_c[df_exec_c['trace_id']>210]\n",
    "    df_exec_c = df_exec_c.sort_values(by=['trace_id'], ascending=False)\n",
    "    df_exec_c = df_exec_c.apply(lambda row: diff_cov(row, df_exec_c), axis=1)\n",
    "    df_exec_c = df_exec_c[df_exec_c['exec'] != 0]\n",
    "\n",
    "    return df_spectra, df_exec_c\n",
    "\n",
    "# set global df_exec_c to store raw coverage data\n",
    "counter = 0\n",
    "verbose = True\n",
    "df_exec_c = []\n",
    "\n",
    "start = time.time()\n",
    "df_spectra, df_exec_c = process_cov(proj_loc, out_loc)\n",
    "\n",
    "# output 1: the coverage spectra [line, fn, file] covered by tests\n",
    "spectra_csv = os.path.join(out_loc, 'spectra.csv')\n",
    "print(\"spectra {}\".format(df_spectra.shape))\n",
    "df_spectra.to_csv(spectra_csv)\n",
    "\n",
    "# output 2: the execution count on each statement `cid` for each trace id [trace_id, cid, exec]\n",
    "exec_csv = os.path.join(out_loc, 'execution.csv')\n",
    "print(\"exec_c {} \".format(df_exec_c.shape))\n",
    "df_exec_c.to_csv(exec_csv, index=False)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02b6436-353f-420c-895f-3a4fe59d4be6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Computing response time\n",
    "\n",
    "This time is based on the creation time of the coverage file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0279e058-c09a-4332-86b9-6c5e97000b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the response time...\n"
     ]
    }
   ],
   "source": [
    "%run cov_tracker.ipynb\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import platform\n",
    "import datetime\n",
    "\n",
    "def get_response_time(proj_loc):\n",
    "    print(\"Computing the response time...\")\n",
    "    lcov_loc = os.path.join(proj_loc, 'seeds_out', 'cov', 'lcov')\n",
    "    # get list of all coverage files\n",
    "    test_files = glob.glob(lcov_loc+'/*_trace.lcov_info_final')\n",
    "    id_dict = {get_trace_id(test_file): test_file for test_file in test_files}\n",
    "    \n",
    "    # info_final\n",
    "    id_dict[-1] = os.path.join(lcov_loc, 'trace.lcov_info_final')\n",
    "    # base lcov\n",
    "    id_dict[-2] = os.path.join(lcov_loc, 'trace.lcov_base')\n",
    "\n",
    "    # collect creation time for all other trace_id\n",
    "    # 1 to skip the last one which might contain no instrumentation when the fuzzing run is manually interrupted\n",
    "    c_time = {}\n",
    "    for trace_id in sorted(id_dict, reverse=True)[1:]:\n",
    "        stat = os.stat(id_dict[trace_id])\n",
    "        if platform.system() == \"Darwin\":\n",
    "            c_timestamp = stat.st_birthtime\n",
    "        elif platform.system() == \"Windows\":\n",
    "            # this might contain bugs, never tested\n",
    "            c_timestamp = os.path.getmtime(id_dict[trace_id])\n",
    "        else:\n",
    "            c_timestamp = stat.st_ctime\n",
    "        c_time[trace_id] = datetime.datetime.fromtimestamp(c_timestamp)\n",
    "        #print(trace_id, c_time[trace_id])\n",
    "        \n",
    "    # compute difference in creation time as the response time\n",
    "    c_time = {i: (time-c_time[i-1]).total_seconds() for i, time in c_time.items() if i >= -1}\n",
    "    df_c_time = pd.DataFrame(list(c_time.items()), columns=['trace_id', 'response_time'])\n",
    "    \n",
    "    return df_c_time\n",
    "\n",
    "df_c_time = get_response_time(proj_loc)\n",
    "\n",
    "# output: response time based on the creation time of the coverage file\n",
    "response_time_csv = os.path.join(out_loc, 'response_time.csv')\n",
    "df_c_time.to_csv(response_time_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c02fad-8f32-4ed7-a53c-a4f4d4081b08",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. Looking for patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9f0b256-b372-4737-8daa-d5c57cb7f2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>exec_c_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[3, 645]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[3, 645]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[3, 645]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[3, 645]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[3, 645]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>2400</td>\n",
       "      <td>[189, 192, 24804]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>2401</td>\n",
       "      <td>[189, 192, 24804]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>2402</td>\n",
       "      <td>[189, 192, 24804]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>2403</td>\n",
       "      <td>[189, 192, 24804]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>2404</td>\n",
       "      <td>[189, 192, 24804]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2405 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cid        exec_c_list\n",
       "0        0           [3, 645]\n",
       "1        1           [3, 645]\n",
       "2        2           [3, 645]\n",
       "3        3           [3, 645]\n",
       "4        4           [3, 645]\n",
       "...    ...                ...\n",
       "2400  2400  [189, 192, 24804]\n",
       "2401  2401  [189, 192, 24804]\n",
       "2402  2402  [189, 192, 24804]\n",
       "2403  2403  [189, 192, 24804]\n",
       "2404  2404  [189, 192, 24804]\n",
       "\n",
       "[2405 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "'''\n",
    "This function groups the tests with similar data flow patterns\n",
    "'''\n",
    "def group_tests():\n",
    "    return\n",
    "\n",
    "'''\n",
    "This function looks for statements that are input sensitive.\n",
    "'''\n",
    "def input_sensitive(row):\n",
    "    \n",
    "    return\n",
    "\n",
    "def get_preprocessed_data(out_loc):\n",
    "    df_spectra = pd.read_csv(os.path.join(out_loc, 'spectra.csv'))\n",
    "    df_exec_c = pd.read_csv(os.path.join(out_loc, 'execution.csv'))\n",
    "    df_response_time = pd.read_csv(os.path.join(out_loc, 'response_time.csv'))\n",
    "    return df_spectra, df_exec_c, df_response_time\n",
    "\n",
    "df_spectra, df_exec_c, df_response_time = get_preprocessed_data(out_loc)\n",
    "\n",
    "df_cid_executed = df_exec_c.groupby('cid')['exec'].apply(lambda row: list(np.unique(row))).reset_index(name='exec_c_list')\n",
    "display(df_cid_executed)\n",
    "cid_executed_csv = os.path.join(out_loc, 'cid_executed.csv')\n",
    "df_cid_executed.to_csv(cid_executed_csv, index=False)\n",
    "# df_exec_c['input_sensitive'] = df_exec_c.apply(lambda row: input_sensitive(row))\n",
    "# likely to be changed by more tests, but less execution counts\n",
    "# likely to be changed by less tests, but more execution counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf9053-8733-42f5-8d62-4b82e662eff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a8466-f8e9-4dfe-8643-effdde4c9cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
