{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c5ef0a-ec50-4e62-a692-4c1942519d5d",
   "metadata": {},
   "source": [
    "# Coverage tracker\n",
    "\n",
    "The purpose of this script is to retrieve and format coverage data produced by `afl-cov`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1970e6ba-fd60-47a1-8ba4-6177b57e54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71282fd6-8bd3-4753-85fb-8bdcb8c42c4d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Format the coverage data by regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "215f00a1-17ed-4c8f-add4-395dea7db14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFuture todos: function execution counts\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Compute coverage data list\n",
    "'''\n",
    "def get_df_da(m):\n",
    "    # list of execution counts  for  each  instrumented  line\n",
    "    # DA:<line number>,<execution count>[,<checksum>]\n",
    "    # execution count is computed in a cumulative fashion\n",
    "    if not m.match(r'^DA:(\\d+),(\\d+)'):\n",
    "        print(\"!DA information missing...\")\n",
    "        return None\n",
    "    \n",
    "    rematch = m.group()\n",
    "    # ignore if exec = 0\n",
    "    return pd.DataFrame([[int(m_obj[0]), int(m_obj[1])] for m_obj in rematch if int(m_obj[1]) != 0], columns=[\"line\", \"exec\"])\n",
    "\n",
    "'''\n",
    "Compute function list\n",
    "'''\n",
    "def get_df_fn(m):\n",
    "    fn_dict = None\n",
    "    # list of functions with their starting line\n",
    "    # FN:<line number of function start>,<function name>\n",
    "    # the function information should be the same regardless\n",
    "    if m.match(r'^FN:(\\d+),(\\w+)'):\n",
    "        rematch = m.group()\n",
    "    return pd.DataFrame([[int(m_obj[0]), m_obj[1]] for m_obj in rematch], columns=[\"line\", \"fn\"])\n",
    "\n",
    "\n",
    "'''\n",
    "Compute function dict\n",
    "'''\n",
    "def get_fn_dict(m):\n",
    "    fn_dict = None\n",
    "    # list of functions with their starting line\n",
    "    # FN:<line number of function start>,<function name>\n",
    "    # the function information should be the same regardless\n",
    "    if m.match(r'^FN:(\\d+),(\\w+)'):\n",
    "        rematch = m.group()\n",
    "    return {m_obj[1]: int(m_obj[0]) for m_obj in rematch}\n",
    "\n",
    "'''\n",
    "Find LH, LH:<number of lines with a non-zero execution count>\n",
    "'''\n",
    "def get_lh(m):\n",
    "    if not m.match(r'^LH:(\\d+)'):\n",
    "        print(\"!LH information missing...\")\n",
    "        return False\n",
    "    \n",
    "    rematch = m.group()[0]\n",
    "    return int(rematch)\n",
    "\n",
    "'''\n",
    "Find SF, SF:<absolute path to the source file>\n",
    "'''\n",
    "def get_sf(m):\n",
    "    if not m.match(r'^SF:(.*)'):\n",
    "        print(\"!SF information missing...\")\n",
    "        return False\n",
    "    \n",
    "    rematch = m.group()[0]\n",
    "    return rematch\n",
    "\n",
    "\n",
    "'''\n",
    "Future todos: branch coverage information\n",
    "'''\n",
    "# branch coverage information is stored which one line per branch\n",
    "# BRDA:<line number>,<block number>,<branch number>,<taken>\n",
    "\n",
    "'''\n",
    "Future todos: function execution counts\n",
    "'''\n",
    "# list of execution counts  for  each  instrumented  function, which is stored in variable `fn`\n",
    "# FNDA:<execution count>,<function name>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838870d7-ee6e-4dc5-bb74-7b2bc1742ade",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Process and compute the coverage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c42b1c-95ec-4fb4-b14e-d3777c1dc383",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Simple regex matcher\n",
    "'''\n",
    "class Matcher(object):\n",
    "    def __init__(self, string):\n",
    "        self.string = string\n",
    "\n",
    "    def match(self,regexp):\n",
    "        self.rematch = re.findall(regexp, self.string, re.MULTILINE)\n",
    "        return bool(self.rematch)\n",
    "\n",
    "    def group(self):\n",
    "        return self.rematch\n",
    "\n",
    "'''\n",
    "Structure the coverage string\n",
    "'''\n",
    "def add_da_to_cov(trace_id, m, info_cov):\n",
    "    if trace_id-1 not in cov and trace_id != 0:\n",
    "        print(\"Error: trace_id\", trace_id-1, \"missing\")\n",
    "        return\n",
    "    # for trace_id after 0, subtract the preceding trace_id's coverage.\n",
    "    if trace_id != 0:\n",
    "        this_cov = {key: cov[trace_id].get(key, 0) - cov[trace_id-1].get(key, 0) for key in cov[trace_id-1]}\n",
    "    else:\n",
    "        this_cov = {key: cov[trace_id].get(key, 0) - info_cov.get(key, 0) for key in info_cov}\n",
    "    print(trace_id, this_cov)\n",
    "    cov[trace_id] = this_cov\n",
    "\n",
    "'''\n",
    "Retrieve trace_id from test_file path\n",
    "'''\n",
    "def get_trace_id(test_file):\n",
    "    trace_id = os.path.basename(test_file)\n",
    "    i1 = trace_id.index('_', 0)+1\n",
    "    i2 = trace_id.index('_', i1)\n",
    "    return int(trace_id[i1:i2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4d2a8-c9bb-4ec7-a4e3-26d7b2e68a82",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Core driver functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28037434-bb7d-4e80-8983-4a23bdb999d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Coverage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a76705-fd93-4078-8ca4-1315172d337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Determine which function a given line belongs to\n",
    "'''\n",
    "def get_fn(row, fn_dict):\n",
    "    line = row['line']\n",
    "    visited = None\n",
    "    for fn, start_line in dict(sorted(fn_dict.items(), key=lambda item: item[1])).items():\n",
    "        if start_line < line:\n",
    "            visited = fn\n",
    "        else:\n",
    "            return visited\n",
    "    return visited\n",
    "\n",
    "'''\n",
    "Compute the code coverage for each source file, store in df_exec_c\n",
    "'''\n",
    "def process_per_sf_cov(trace_id, test_file):\n",
    "    global df_exec_c\n",
    "    \n",
    "    # build matcher object for coverage string\n",
    "    cov_str = read_file_as_str(test_file)\n",
    "\n",
    "    # for file\n",
    "    sf_str_list = cov_str.split(\"end_of_record\")\n",
    "    # -1 to skip the `end_of_record` string\n",
    "    for cov_str in sf_str_list[:-1]:\n",
    "        m = Matcher(cov_str)\n",
    "        # skip if the instrumented lines is 0\n",
    "        if(get_lh(m) == 0):\n",
    "            continue\n",
    "\n",
    "        # compute coverage\n",
    "        df_da = get_df_da(m)\n",
    "        df_da['trace_id'] = trace_id\n",
    "        # find the source file and use the relative path\n",
    "        df_da['file'] = os.path.relpath(get_sf(m), proj_loc)\n",
    "        df_da = df_da[df_da['exec'] != 0]\n",
    "        # find the corresponding function\n",
    "        # !this slows down the pre-processing but just in case that some test cases might have different functions\n",
    "        fn_dict = get_fn_dict(m)\n",
    "        df_da['fn'] = df_da.apply(lambda row: get_fn(row, fn_dict), axis=1)\n",
    "        \n",
    "        df_exec_c.append(df_da)\n",
    "\n",
    "'''\n",
    "Get code coverage from test cases/inputs generated by AFL\n",
    "'''\n",
    "def collect_cov(proj_loc):\n",
    "    global df_exec_c, fn_dict\n",
    "    \n",
    "    lcov_loc = os.path.join(proj_loc, 'seeds_out', 'cov', 'lcov')\n",
    "    # get list of all coverage files\n",
    "    test_files = glob.glob(lcov_loc+'/*_trace.lcov_info_final')\n",
    "    id_dict = {get_trace_id(test_file): test_file for test_file in test_files}\n",
    "    \n",
    "    # collect coverage for info file\n",
    "    info_trace_file = os.path.join(lcov_loc, 'trace.lcov_info_final')\n",
    "    # add source file coverage to df_exec_c\n",
    "    process_per_sf_cov(-1, info_trace_file)\n",
    "    \n",
    "    # collect coverage for all other trace_id\n",
    "    # -1 to skip the last one which might contain no instrumentation when the fuzzing run is manually interrupted\n",
    "    for trace_id in sorted(id_dict)[:-1]:\n",
    "        #print(\"Trace\", trace_id)\n",
    "        test_file = id_dict[trace_id]\n",
    "        # add source file coverage to df_exec_c\n",
    "        process_per_sf_cov(trace_id, test_file)\n",
    "         \n",
    "    # combine all df into one single df\n",
    "    df_exec_c = pd.concat(df_exec_c)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec4b3df-5fd5-4f1a-a2a2-161e7a457a77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Spectra computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6861b40d-5550-467a-a48f-b2e1aed4dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compute the coverage spectra\n",
    "'''\n",
    "def compute_cov_spectra(df_exec_c):\n",
    "    df_cov_spectra = df_exec_c[['line', 'fn', 'file']]\n",
    "    df_cov_spectra = df_cov_spectra.drop_duplicates(subset=['line', 'fn', 'file'])\n",
    "    \n",
    "    # sort\n",
    "    df_cov_spectra = df_cov_spectra.sort_values(by=['file', 'line']).reset_index(drop=True)\n",
    "    df_cov_spectra.index.name = \"cid\"\n",
    "    \n",
    "    return df_cov_spectra.reset_index()\n",
    "\n",
    "'''\n",
    "Preprocess code coverage, reshape the data to optimize the processing time\n",
    "'''\n",
    "def preprocess_cov(spectra_csv, exec_c_csv):\n",
    "    global df_exec_c\n",
    "    \n",
    "    shape = df_exec_c.shape\n",
    "    # format the code coverage\n",
    "    df_spectra = compute_cov_spectra(df_exec_c)\n",
    "    # format the execution count\n",
    "    df_exec_c = pd.merge(df_exec_c, df_spectra.reset_index(),  how='outer', on=['line', 'file', 'fn'])\n",
    "    df_exec_c = df_exec_c[['trace_id', 'cid', 'exec']].sort_values(by=['trace_id', 'cid'])\n",
    "    print(\"\\tprocessed coverage shape {} -> exec_c {} & spectra {}\".format(shape, df_exec_c.shape, df_spectra.shape))\n",
    "\n",
    "    df_spectra.to_csv(spectra_csv, encoding='utf-8', index=False)\n",
    "    df_exec_c.to_csv(exec_c_csv, encoding='utf-8', index=False)\n",
    "    return df_spectra, df_exec_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ba48eb-f8ab-4b38-9aff-96600774a680",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Individual coveration processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff69d6c-cab6-4b84-8a08-90e8c96d6eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Process the coverage backward by subtracting the last trace_id by the before last one to compute the diff\n",
    "'''\n",
    "def diff_cov(row, df_exec_c):\n",
    "    global counter, verbose\n",
    "    \n",
    "    exec_c, trace_id, cid = row['exec'], row['trace_id'], row['cid']\n",
    "    \n",
    "    if verbose:\n",
    "        counter = counter + 1\n",
    "        if (counter % 1000) == 0:\n",
    "            print(\"counter at\", counter)\n",
    "    \n",
    "    # select next_row to compute the diff, note that info_trace takes the trace_id of -1\n",
    "    next_row = df_exec_c[(df_exec_c[\"trace_id\"] < trace_id) & (df_exec_c['cid'] == cid)]\n",
    "    \n",
    "    if next_row.empty:\n",
    "        return row\n",
    "    else:\n",
    "        # always subtract by the highest exec, which should be the next instrumented test\n",
    "        row['exec'] = row['exec'] - next_row['exec'].max()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62af81f-1cb2-482c-bb8a-5af0ac005866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
