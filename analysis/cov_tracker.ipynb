{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c5ef0a-ec50-4e62-a692-4c1942519d5d",
   "metadata": {},
   "source": [
    "# Coverage tracker\n",
    "\n",
    "The purpose of this script is to retrieve and format coverage data produced by `afl-cov`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1970e6ba-fd60-47a1-8ba4-6177b57e54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71282fd6-8bd3-4753-85fb-8bdcb8c42c4d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Format the coverage data by regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "215f00a1-17ed-4c8f-add4-395dea7db14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFuture todos: function execution counts\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Compute function dict\n",
    "'''\n",
    "def get_fn_dict(m):\n",
    "    fn_dict = None\n",
    "    # list of functions with their starting line\n",
    "    # FN:<line number of function start>,<function name>\n",
    "    # the function information should be the same regardless\n",
    "    if not has_fn_dict and m.match(r'^FN:(\\d+),(\\w+)'):\n",
    "        rematch = m.group()\n",
    "        fn_dict = {m_obj[1]: {'start_line': int(m_obj[0])} for m_obj in rematch}\n",
    "    return fn_dict\n",
    "\n",
    "'''\n",
    "Compute data dict\n",
    "'''\n",
    "def get_da_dict(m):\n",
    "    # list of execution counts  for  each  instrumented  line\n",
    "    # DA:<line number>,<execution count>[,<checksum>]\n",
    "    # execution count is computed in a cumulative fashion\n",
    "    if not m.match(r'^DA:(\\d+),(\\d+)'):\n",
    "        print(\"!DA information missing...\")\n",
    "        return\n",
    "    \n",
    "    rematch = m.group()\n",
    "    this_cov = {int(m_obj[0]): int(m_obj[1]) for m_obj in rematch}\n",
    "    return this_cov\n",
    "\n",
    "'''\n",
    "Future todos: branch coverage information\n",
    "'''\n",
    "# branch coverage information is stored which one line per branch\n",
    "# BRDA:<line number>,<block number>,<branch number>,<taken>\n",
    "\n",
    "'''\n",
    "Future todos: function execution counts\n",
    "'''\n",
    "# list of execution counts  for  each  instrumented  function, which is stored in variable `fn`\n",
    "# FNDA:<execution count>,<function name>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838870d7-ee6e-4dc5-bb74-7b2bc1742ade",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Process and compute the coverage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c42b1c-95ec-4fb4-b14e-d3777c1dc383",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Simple regex matcher\n",
    "'''\n",
    "class Matcher(object):\n",
    "    def __init__(self, string):\n",
    "        self.string = string\n",
    "\n",
    "    def match(self,regexp):\n",
    "        self.rematch = re.findall(regexp, self.string, re.MULTILINE)\n",
    "        return bool(self.rematch)\n",
    "\n",
    "    def group(self):\n",
    "        return self.rematch\n",
    "    \n",
    "'''\n",
    "Compute the coverage for info trace\n",
    "'''\n",
    "def get_cov_info_trace(info_trace_file):\n",
    "    cov_str = read_file_as_str(info_trace_file)\n",
    "    m = Matcher(cov_str)\n",
    "    return get_da_dict(m), get_fn_dict(m)\n",
    "\n",
    "'''\n",
    "Structure the coverage string\n",
    "'''\n",
    "def add_da_to_cov(trace_id, m, info_cov):\n",
    "    if trace_id-1 not in cov and trace_id != 0:\n",
    "        print(\"Error: trace_id\", trace_id-1, \"missing\")\n",
    "        return\n",
    "    # for trace_id after 0, subtract the preceding trace_id's coverage.\n",
    "    if trace_id != 0:\n",
    "        this_cov = {key: cov[trace_id].get(key, 0) - cov[trace_id-1].get(key, 0) for key in cov[trace_id-1]}\n",
    "    else:\n",
    "        this_cov = {key: cov[trace_id].get(key, 0) - info_cov.get(key, 0) for key in info_cov}\n",
    "    print(trace_id, this_cov)\n",
    "    cov[trace_id] = this_cov\n",
    "\n",
    "'''\n",
    "Retrieve trace_id from test_file path\n",
    "'''\n",
    "def get_trace_id(test_file):\n",
    "    trace_id = os.path.basename(test_file)\n",
    "    i1 = trace_id.index('_', 0)+1\n",
    "    i2 = trace_id.index('_', i1)\n",
    "    return int(trace_id[i1:i2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4d2a8-c9bb-4ec7-a4e3-26d7b2e68a82",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Core driver functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a76705-fd93-4078-8ca4-1315172d337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Process code coverage and store the output into cov.csv and exec_c.csv for coverage and execution counts \n",
    "[\"cid\", \"file\", \"line\", \"fn\"]\n",
    "'''\n",
    "def process_cov(proj_loc, out_loc):\n",
    "    get_test_cov(proj_loc)\n",
    "    pd_cov = list(set([line for k, v in cov.items() for line in v.keys()]))\n",
    "    pd_cov = pd.DataFrame([pd_cov], columns=[\"cid\", \"line\"])\n",
    "    display(pd_cov)\n",
    "\n",
    "'''\n",
    "Get code coverage from test cases/inputs generated by AFL\n",
    "'''\n",
    "def get_test_cov(proj_loc):\n",
    "    global cov\n",
    "    lcov_loc = os.path.join(proj_loc, 'isort-seeds-out', 'cov', 'lcov')\n",
    "    \n",
    "    # info_cov is used to compute the coverage of the first test case, because the da and fnda values are cumulative\n",
    "    info_cov = {}\n",
    "    # for initial info trace file\n",
    "    info_trace_file = os.path.join(lcov_loc, 'trace.lcov_info_final')\n",
    "    info_cov, fn_dict = get_cov_info_trace(info_trace_file)\n",
    "    #print(\"Initial info trace: {} out of {} lines were covered\".format(len([k for k, v in info_cov.items() if v!=0]), len(info_cov)))\n",
    "    #print(\"{} functions\".format(len(fn_dict)))\n",
    "    \n",
    "    test_files = glob.glob(lcov_loc+'/*_trace.lcov_info_final')\n",
    "    id_dict = {get_trace_id(test_file): test_file for test_file in test_files}\n",
    "    \n",
    "    # get all cov first\n",
    "    for trace_id in sorted(id_dict):\n",
    "        # todo: capture each end_of_record\n",
    "        # todo: skip if LH is null, which means there was no coverage hit\n",
    "        test_file = id_dict[trace_id]\n",
    "        \n",
    "        # build matcher object for coverage string\n",
    "        cov_str = read_file_as_str(test_file)\n",
    "        m = Matcher(cov_str)\n",
    "        # compute coverage\n",
    "        cov[trace_id] = get_da_dict(m)\n",
    "    \n",
    "    # sorted reverse, start from the last trace_id, process the coverage backward by subtracting the last trace_id by the before last one to compute the diff\n",
    "    # ignore last trace_id as it may be incomplete\n",
    "    for trace_id in sorted(id_dict, reverse=True)[1:]:\n",
    "        add_da_to_cov(trace_id, m, info_cov)\n",
    "        #print(\"Test case {}: {}/{}\".format(trace_id, len([k for k, v in cov[trace_id].items() if v!=0]), len(cov[trace_id])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
